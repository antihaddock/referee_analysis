{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('./data/Appointments/2022 MatchRef for Ryan.xlsx')\n",
    "df = df.drop(columns=['association', 'matchno', 'histyear', 'postype','referee'])\n",
    "\n",
    "npl_men_start = '2022-03-11'\n",
    "npl_women_start = '2022-03-18'\n",
    "zpl_start = '2022-04-23'\n",
    "zl_start = '2022-04-09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = [' Interdistrict 25 A',\n",
    "  \" NPL Men's \",\n",
    "  ' NL1 1st', \n",
    "  ' NL1 18',\n",
    "  ' NL1 Res',\n",
    "  ' ZL1 Res',\n",
    "  ' ZL1 1st',\n",
    "  ' Australia ',\n",
    "  ' ZL1 3rd',\n",
    "  ' ZPL 3rd',\n",
    "  ' ZPL Res',\n",
    "  ' ZPL 1st',\n",
    "  ' ZL2 Res',\n",
    "  ' ZL2 1st',\n",
    "  ' ZL3 Res',\n",
    "  ' ZL3 1st',\n",
    "  ' NPL 18',\n",
    "  \" NPL Women'\",\n",
    "  ' NPL Res',\n",
    "  ' NPL 1st',\n",
    "  ' FNSWNPL18',\n",
    "  ' FNSWNPL20',\n",
    "  ' FNSWNPL1st']\n",
    "\n",
    "df_filtered = df[df['matchgrade'].isin(comps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered[df_filtered['matchgrade'].isin([\" NPL Men's \",' NPL 1st'])]\n",
    "# NPL start date\n",
    "df_filtered['before_npl_start'] = df_filtered['matchdate']==npl_start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 2015:\n",
      "Index(['Name', 'Date', 'Item/Acct', 'Description'], dtype='object')\n",
      "\n",
      "Columns in 2016 - 2018:\n",
      "Index(['name', 'position', 'matchdate', 'matchgrade', 'kickoff', 'ground',\n",
      "       'hometeam', 'awayteam', 'Year'],\n",
      "      dtype='object')\n",
      "\n",
      "Columns in 2012:\n",
      "Index(['Name', 'Date', 'Item/Acct', 'Description'], dtype='object')\n",
      "\n",
      "Columns in 2010-2011:\n",
      "Index(['name', 'Date', 'Item/Acct', 'Description'], dtype='object')\n",
      "\n",
      "Columns in 2009:\n",
      "Index(['Name', 'Date', 'Item/Acct', 'Description'], dtype='object')\n",
      "\n",
      "Columns in 2013-2014:\n",
      "Index(['Name', 'Date', 'Item/Acct', 'Description'], dtype='object')\n",
      "\n",
      "Columns in 2022:\n",
      "Index(['association', 'matchno', 'histyear', 'referee', 'name', 'postype',\n",
      "       'position', 'matchdate', 'matchgrade', 'kickoff', 'ground', 'hometeam',\n",
      "       'awayteam'],\n",
      "      dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Move into the ./data/Appointments subdirectory\n",
    "subdirectory = './data/Appointments'\n",
    "os.chdir(subdirectory)\n",
    "\n",
    "# Get a list of all the files in the subdirectory\n",
    "files = os.listdir()\n",
    "\n",
    "# Filter the list to only include xlsx files\n",
    "xlsx_files = [file for file in files if file.endswith('.xlsx')]\n",
    "\n",
    "# Loop over each xlsx file and read it into a pandas dataframe\n",
    "dataframes = {}\n",
    "for file in xlsx_files:\n",
    "    dataframe_name = file.split('.')[0]\n",
    "    dataframe = pd.read_excel(file)\n",
    "    dataframes[dataframe_name] = dataframe\n",
    "\n",
    "# Loop over each dataframe and print out the column names\n",
    "for dataframe_name, dataframe in dataframes.items():\n",
    "    print(f\"Columns in {dataframe_name}:\")\n",
    "    print(dataframe.columns)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can concat 2015, 2009, 2012, 2010-2011 & 2013-2014 together into 1 file\n",
    "# can concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Index(...) must be called with a collection of some kind, '2012' was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_417/3860383354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcombined_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatching_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcombined_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reset the index of the concatenated dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcombined_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_name\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set a custom name for the concatenated dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataframe_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatching_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Remove the old matching dataframe from the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mrename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   5084\u001b[0m         \u001b[0;36m4\u001b[0m  \u001b[0;36m3\u001b[0m  \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5085\u001b[0m         \"\"\"\n\u001b[0;32m-> 5086\u001b[0;31m         return super()._rename(\n\u001b[0m\u001b[1;32m   5087\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5088\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_rename\u001b[0;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplacements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   5776\u001b[0m         \"\"\"\n\u001b[1;32m   5777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5778\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5779\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5780\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3722\u001b[0m     ) -> npt.NDArray[np.intp]:\n\u001b[1;32m   3723\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_reindex_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3724\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_listlike_indexer\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6309\u001b[0m         \u001b[0mAnalogue\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaybe_cast_indexer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mget_indexer\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6310\u001b[0m         \"\"\"\n\u001b[0;32m-> 6311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6313\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7059\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7060\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_with_infer\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".*the Index constructor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_dtype_obj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_multi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scalar_data_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__array__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Index(...) must be called with a collection of some kind, '2012' was passed"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Move into the ./data/Appointments subdirectory\n",
    "#subdirectory = './data/Appointments'\n",
    "#os.chdir(subdirectory)\n",
    "\n",
    "# Get a list of all the files in the subdirectory\n",
    "files = os.listdir()\n",
    "\n",
    "# Filter the list to only include xlsx files\n",
    "xlsx_files = [file for file in files if file.endswith('.xlsx')]\n",
    "\n",
    "# Loop over each xlsx file and read it into a pandas dataframe\n",
    "dataframes = {}\n",
    "for file in xlsx_files:\n",
    "    dataframe_name = file.split('.')[0]\n",
    "    dataframe = pd.read_excel(file)\n",
    "    \n",
    "    # Check if this dataframe has any column names in common with existing dataframes\n",
    "    matching_dataframes = [df for df in dataframes.values() if set(df.columns) == set(dataframe.columns)]\n",
    "    \n",
    "    if len(matching_dataframes) > 0:\n",
    "        # If we found a matching dataframe, concatenate this dataframe with the first matching one\n",
    "        matching_dataframe = matching_dataframes[0]\n",
    "        combined_dataframe = pd.concat([matching_dataframe, dataframe])\n",
    "        combined_dataframe = combined_dataframe.reset_index(drop=True)  # Reset the index of the concatenated dataframe\n",
    "        combined_dataframe = combined_dataframe.rename(dataframe_name)  # Set a custom name for the concatenated dataframe\n",
    "        dataframes[dataframe_name] = combined_dataframe\n",
    "        del dataframes[matching_dataframe.columns.tolist()]  # Remove the old matching dataframe from the dictionary\n",
    "    else:\n",
    "        # If we didn't find a matching dataframe, add this one to the dictionary as-is\n",
    "        dataframes[dataframe_name] = dataframe\n",
    "\n",
    "# Loop over each dataframe and print out the column names\n",
    "for dataframe_name, dataframe in dataframes.items():\n",
    "    print(f\"Columns in {dataframe_name}:\")\n",
    "    print(dataframe.columns)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2015.xlsx',\n",
       " '2016 - 2018.xlsx',\n",
       " '2012.xlsx',\n",
       " '2010-2011.xlsx',\n",
       " '2009.xlsx',\n",
       " '2013-2014.xlsx',\n",
       " '2021.csv',\n",
       " '2020.csv',\n",
       " '2022.xlsx',\n",
       " '2019.csv']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/antihaddock/Repos/ref_analysis/data/Appointments/2015.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2016 - 2018.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2012.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2010-2011.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2009.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2013-2014.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2021.csv', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2020.csv', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2022.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Appointments/2019.csv', '/home/antihaddock/Repos/ref_analysis/data/Disciplinary/2022 Yellow Card Register MASTER.xlsx', '/home/antihaddock/Repos/ref_analysis/data/Disciplinary/2022 Suspension Register MASTER.xlsx']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_files(path):\n",
    "    files = []\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            files.append(os.path.join(r, file))\n",
    "    return files\n",
    "\n",
    "path = '/home/antihaddock/Repos/ref_analysis/data/'\n",
    "files = get_files(path)\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2015.xlsx\n",
      "Name           object\n",
      "Date           object\n",
      "Description    object\n",
      "Position       object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2016 - 2018.xlsx\n",
      "name                  object\n",
      "position              object\n",
      "matchdate     datetime64[ns]\n",
      "matchgrade            object\n",
      "kickoff               object\n",
      "ground                object\n",
      "hometeam              object\n",
      "awayteam              object\n",
      "Year                   int64\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2012.xlsx\n",
      "Name           object\n",
      "Date           object\n",
      "Description    object\n",
      "Position       object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2010-2011.xlsx\n",
      "name           object\n",
      "Date           object\n",
      "Description    object\n",
      "Position       object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2009.xlsx\n",
      "Name           object\n",
      "Date           object\n",
      "Description    object\n",
      "Position       object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2013-2014.xlsx\n",
      "Name                   object\n",
      "Date           datetime64[ns]\n",
      "Description            object\n",
      "Position               object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2021.csv\n",
      "name          object\n",
      "position      object\n",
      "matchgrade    object\n",
      "matchdate     object\n",
      "kickoff       object\n",
      "ground        object\n",
      "hometeam      object\n",
      "awayteam      object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2020.csv\n",
      "association     object\n",
      "matchno        float64\n",
      "histyear       float64\n",
      "referee        float64\n",
      "name            object\n",
      "postype        float64\n",
      "position        object\n",
      "matchdate       object\n",
      "matchgrade      object\n",
      "kickoff         object\n",
      "ground          object\n",
      "hometeam        object\n",
      "awayteam        object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2022.xlsx\n",
      "association            object\n",
      "matchno               float64\n",
      "histyear              float64\n",
      "referee               float64\n",
      "name                   object\n",
      "postype               float64\n",
      "position               object\n",
      "matchdate      datetime64[ns]\n",
      "matchgrade             object\n",
      "kickoff                object\n",
      "ground                 object\n",
      "hometeam               object\n",
      "awayteam               object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Appointments/2019.csv\n",
      "dassociation    object\n",
      "matchno          int64\n",
      "histyear         int64\n",
      "referee          int64\n",
      "name            object\n",
      "postype          int64\n",
      "position        object\n",
      "matchdate       object\n",
      "matchgrade      object\n",
      "kickoff         object\n",
      "ground          object\n",
      "hometeam        object\n",
      "awayteam        object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Disciplinary/2022 Yellow Card Register MASTER.xlsx\n",
      "ROUND                           object\n",
      "COMPETITION                     object\n",
      "GRADE                           object\n",
      "DATE                    datetime64[ns]\n",
      "VENUE                           object\n",
      "FIRST NAME                      object\n",
      "SURNAME                         object\n",
      "CLUB                            object\n",
      "INFRINGEMENT                    object\n",
      "PLAYER/TEAM OFFICIAL            object\n",
      "COUNT                            int64\n",
      "NOTES                           object\n",
      "dtype: object\n",
      "/home/antihaddock/Repos/ref_analysis/data/Disciplinary/2022 Suspension Register MASTER.xlsx\n",
      "DATE OF NOTICE                      datetime64[ns]\n",
      "ROUND                                       object\n",
      "MATCH DAY                                   object\n",
      "GRADE                                       object\n",
      "DATE of INFRINGEMENT                datetime64[ns]\n",
      "VENUE                                       object\n",
      "OPPOSITION CLUB                             object\n",
      "FIRST NAME                                  object\n",
      "SURNAME                                     object\n",
      "FFA Number                                   int64\n",
      "CLUB                                        object\n",
      "CLUB EMAIL                                  object\n",
      "CODE                                        object\n",
      "OFFENCE                                     object\n",
      "GRADING                                     object\n",
      "After Send off Code                         object\n",
      "After Send off Offence                      object\n",
      "After Send off GRADING                      object\n",
      "SUSPENSION MATCHES                          object\n",
      "AUTO PLUS + (ADDITIONAL MATCHES)           float64\n",
      "NOTES                                       object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antihaddock/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "        # take the path of the file and return just its name without spaces to come up \n",
    "        # with the Big Query Table name\n",
    "        bq_table_name = os.path.splitext(os.path.basename(file))[0].replace(\" \", \"\")   \n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(file, low_memory=False)\n",
    "        elif file.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file)\n",
    "        else:\n",
    "            print(f\"{file} is not a CSV or XLSX file.\")\n",
    "            \n",
    "        #Check for column names BQ doesn't like\n",
    "        if \"Item/Acct\" in df.columns:\n",
    "        # replace the column with a new column named \"Position\"\n",
    "            df[\"Position\"] = df[\"Item/Acct\"]\n",
    "            df.drop(\"Item/Acct\", axis=1, inplace=True)\n",
    "            \n",
    "        # # Fix issue with date time columns throwing errors for BQ\n",
    "        # object_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "        # for column in object_cols:\n",
    "        #     dtype = str(type(df[column].values[0]))\n",
    "        #     if dtype == \"<class 'datetime.date'>\":\n",
    "        #         df[column]  = pd.to_datetime(df[column] , infer_datetime_format=True)(\" \", \"\")\n",
    "        #         print(\"I Changed a Column\")\n",
    "            \n",
    "        # for col in df.columns:\n",
    "        #     #if df[col].dtype == 'datetime64[ns]':\n",
    "        #     # convert the column to pandas datetime format\n",
    "        #         #df[col] = pd.to_datetime(df[col])\n",
    "        #         df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
    "        #         print('I changed a column')\n",
    "                \n",
    "        print(file)\n",
    "        print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "association            object\n",
       "matchno               float64\n",
       "histyear              float64\n",
       "referee               float64\n",
       "name                   object\n",
       "postype               float64\n",
       "position               object\n",
       "matchdate      datetime64[ns]\n",
       "matchgrade             object\n",
       "kickoff                object\n",
       "ground                 object\n",
       "hometeam               object\n",
       "awayteam               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('/home/antihaddock/Repos/ref_analysis/data/Appointments/2022.xlsx')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2016-2018.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2013-2014.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2022.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2022SuspensionRegisterMASTER.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2020.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2022YellowCardRegisterMASTER.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2012.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2015.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2009.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2010-2011.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2021.parquet\n",
      "file name is: /home/antihaddock/Repos/ref_analysis/data/parquets/2019.parquet\n"
     ]
    }
   ],
   "source": [
    "def get_files(path):\n",
    "    \"\"\" A function to find all files in a directory and save the path into a list\"\"\" \n",
    "    files = []\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            files.append(os.path.join(r, file))\n",
    "    return files\n",
    "\n",
    "files = get_files('/home/antihaddock/Repos/ref_analysis/data/parquets/')\n",
    "for file in files:\n",
    "        print(f'file name is: {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['matchgrade'].astype(int)\n",
    "df['matchgrade'] = df['matchgrade'].astype(bytes)#.encode('utf-8')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
